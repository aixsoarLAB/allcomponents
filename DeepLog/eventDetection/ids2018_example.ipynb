{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# 將包含 deeplog 模組的目錄路徑添加到 sys.path\n",
    "sys.path.append('../DeepLog/deeplog')\n",
    "# import DeepLog and Preprocessor\n",
    "from deeplog              import DeepLog\n",
    "from preprocessor import Preprocessor\n",
    "# Import pytorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[53, 53, 53,  ..., 53, 53, 53],\n",
      "        [53, 53, 53,  ..., 53, 53, 41],\n",
      "        [53, 53, 53,  ..., 53, 41, 41],\n",
      "        ...,\n",
      "        [40, 41, 38,  ..., 38, 40, 41],\n",
      "        [41, 38, 40,  ..., 40, 41, 41],\n",
      "        [38, 40, 41,  ..., 41, 41, 38]]) \n",
      "Shape: torch.Size([114026, 20]) \n",
      "mapping: {0: 1, 1: 2, 2: 6, 3: 12, 4: 13, 5: 14, 6: 15, 7: 16, 8: 18, 9: 19, 10: 20, 11: 25, 12: 27, 13: 32, 14: 35, 15: 37, 16: 43, 17: 44, 18: 47, 19: 50, 20: 55, 21: 98, 22: 109, 23: 153, 24: 172, 25: 1014, 26: 1074, 27: 4200, 28: 6005, 29: 6006, 30: 6009, 31: 6013, 32: 7000, 33: 7001, 34: 7002, 35: 7009, 36: 7022, 37: 7023, 38: 7024, 39: 7026, 40: 7031, 41: 7036, 42: 7040, 43: 7042, 44: 7045, 45: 10010, 46: 10016, 47: 10148, 48: 16962, 49: 50036, 50: 50037, 51: 51046, 52: 51047, 53: -1337}\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "#                                 Load data                                  #\n",
    "##############################################################################\n",
    "\n",
    "# Create preprocessor for cd loading data\n",
    "preprocessor = Preprocessor(\n",
    "    length  = 20,           # Extract sequences of 20 items\n",
    "    timeout = float('inf'), # Do not include a maximum allowed time between events\n",
    ")\n",
    "\n",
    "training_data_path = \"./data/IDS2018_train_benign\"\n",
    "\n",
    "# Load data from csv file\n",
    "#X, y, label, mapping = preprocessor.csv(training_data_path)\n",
    "# Load data from txt file\n",
    "X, y, label, mapping = preprocessor.text(training_data_path)\n",
    "\n",
    "print(\"X:\", X, \"\\nShape:\", X.shape, \"\\nmapping:\", mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1/10] average loss = 2.1706 ######################################## (100.00%) runtime 0:00:33.2\n",
      "[Epoch  2/10] average loss = 1.3509 ######################################## (100.00%) runtime 0:00:34.9\n",
      "[Epoch  3/10] average loss = 1.3430 ######################################## (100.00%) runtime 0:00:32.0\n",
      "[Epoch  4/10] average loss = 1.3361 ######################################## (100.00%) runtime 0:00:35.2\n",
      "[Epoch  5/10] average loss = 1.3295 ######################################## (100.00%) runtime 0:00:32.9\n",
      "[Epoch  6/10] average loss = 1.3195 ######################################## (100.00%) runtime 0:00:32.7\n",
      "[Epoch  7/10] average loss = 1.2444 ######################################## (100.00%) runtime 0:00:35.3\n",
      "[Epoch  8/10] average loss = 1.1856 ######################################## (100.00%) runtime 0:00:33.6\n",
      "[Epoch  9/10] average loss = 1.1670 ######################################## (100.00%) runtime 0:00:33.0\n",
      "[Epoch 10/10] average loss = 1.1496 ######################################## (100.00%) runtime 0:00:31.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepLog(\n",
       "  (lstm): LSTM(60, 64, num_layers=2, batch_first=True)\n",
       "  (out): Linear(in_features=64, out_features=100, bias=True)\n",
       "  (softmax): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################################################\n",
    "#                                  DeepLog                                   #\n",
    "##############################################################################\n",
    "\n",
    "# Create DeepLog object\n",
    "deeplog = DeepLog(\n",
    "    input_size  = 60, # Number of different events to expect\n",
    "    hidden_size = 64 , # Hidden dimension, we suggest 64\n",
    "    output_size = 100, # Number of different events to expect\n",
    ")\n",
    "\n",
    "# Optionally cast data and DeepLog to cuda, if available\n",
    "if torch.cuda.is_available():\n",
    "    deeplog = deeplog.to(\"cuda\")\n",
    "    X       = X      .to(\"cuda\")\n",
    "    y       = y      .to(\"cuda\")\n",
    "\n",
    "# Train deeplog\n",
    "deeplog.fit(\n",
    "    X          = X,\n",
    "    y          = y,\n",
    "    epochs     = 10,\n",
    "    batch_size = 128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xp: tensor([[15, 15, 15,  ..., 15, 15, 15],\n",
      "        [15, 15, 15,  ..., 15, 15,  4],\n",
      "        [15, 15, 15,  ..., 15,  4, 12],\n",
      "        ...,\n",
      "        [12, 13,  7,  ..., 12, 12, 12],\n",
      "        [13,  7,  5,  ..., 12, 12, 10],\n",
      "        [ 7,  5,  6,  ..., 12, 10, 11]]) \n",
      "Shape: torch.Size([114026, 20]) \n",
      "mapping_p: {0: 2, 1: 16, 2: 35, 3: 37, 4: 104, 5: 134, 6: 4200, 7: 4201, 8: 7000, 9: 7009, 10: 7024, 11: 7031, 12: 7036, 13: 7045, 14: 20001, 15: -1337}\n",
      "[Epoch 1/1] average loss = 0.0000 ######################################## (100.00%) runtime 0:00:00.2\n",
      "y_pred: tensor([[41, 40, 38,  ...,  0,  7, 15],\n",
      "        [41, 40, 38,  ...,  0,  7, 15],\n",
      "        [41, 40, 38,  ...,  0,  7, 15],\n",
      "        ...,\n",
      "        [41, 40, 38,  ...,  0,  7, 15],\n",
      "        [41, 40, 38,  ...,  0,  7, 15],\n",
      "        [41, 40, 38,  ...,  0,  7, 15]]) \n",
      "shape: torch.Size([226, 9])\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "#                                  Predict                                   #\n",
    "##############################################################################\n",
    "\n",
    "data_path = \"./data/IDS2018_test_abnormal_Infiltration\"\n",
    "\n",
    "# Load data from csv file\n",
    "#Xp, yp, label, mapping_p = preprocessor.csv(\"/home/ubuntu/DeepLog/examples/data/hdfs_train\")\n",
    "# Load data from txt file\n",
    "Xp, yp, label, mapping_p = preprocessor.text(data_path)\n",
    "print(\"Xp:\", Xp, \"\\nShape:\", X.shape, \"\\nmapping_p:\", mapping_p)\n",
    "\n",
    "# Predict using deeplog\n",
    "y_pred, confidence = deeplog.predict(\n",
    "    X = Xp,\n",
    "    k = 9,\n",
    ")\n",
    "\n",
    "print(\"y_pred:\", y_pred, \"\\nshape:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: ['104', '7036', '16', '7036', '7024', '7031', '7036', '7009', '7000', '7036', '7036', '7036', '37', '35', '7036', '7036', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7024', '7031', '7036', '7036', '7036', '7036', '2', '7036', '7036', '7036', '7036', '7045', '20001', '7036', '7036', '7024', '7031', '7036', '7036', '7036', '7036', '7045', '4201', '134', '4200', '4200', '37', '16', '7036', '37', '7036', '7036', '7036', '7024', '7031', '7036', '7036', '7036', '7036', '7036', '7024', '7031', '7036'] \n",
      "size: 226\n",
      "mapped_data: [4, 12, 1, 12, 10, 11, 12, 9, 8, 12, 12, 12, 3, 2, 12, 12, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 10, 11, 12, 12, 12, 12, 0, 12, 12, 12, 12, 13, 14, 12, 12, 10, 11, 12, 12, 12, 12, 13, 7, 5, 6, 6, 3, 1, 12, 3, 12, 12, 12, 10, 11, 12, 12, 12, 12, 12, 10, 11, 12] \n",
      "size: 226\n",
      "results: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "size: 226\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "#                                 Comparison                                 #\n",
    "##############################################################################\n",
    "\n",
    "# 讀取測試文件\n",
    "with open(data_path, 'r') as file:\n",
    "    data = file.readlines()\n",
    "\n",
    "cleaned_data = [item.strip() for item in data]\n",
    "\n",
    "# 使用列表推導式分隔每個字串，並將結果扁平化形成一個新的串列\n",
    "data = [item for sublist in cleaned_data for item in sublist.split()]\n",
    "\n",
    "print(\"data:\", data, \"\\nsize:\", len(data))\n",
    "\n",
    "# 反轉 mapping，以便我們可以根據事件ID找到對應的編號\n",
    "reverse_mapping = {v: k for k, v in mapping_p.items()}\n",
    "\n",
    "# 轉換 events 列表中的每個字串為數字，然後根據 reverse_mapping 進行映射\n",
    "mapped_data = [reverse_mapping[int(event)] for event in data]\n",
    "\n",
    "print(\"mapped_data:\", mapped_data, \"\\nsize:\", len(mapped_data))\n",
    "\n",
    "# 初始化一個零張量，用於存儲比較結果，長度與 test_normal_data 相同\n",
    "results = []\n",
    "\n",
    "# 遍歷 test_normal_data 的每一行\n",
    "for i in range(0, len(mapped_data)):\n",
    "    match = False\n",
    "    for j in y_pred[i]:\n",
    "        if mapped_data[i] == j:\n",
    "            match = True\n",
    "            break\n",
    "    \n",
    "    # 如果有匹配，設置結果為1\n",
    "    if match:\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "print(\"results:\", results, \"\\nsize:\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "異常數量：223\n",
      "異常率：0.987\n"
     ]
    }
   ],
   "source": [
    "# 計算列表中0的數量\n",
    "num_of_zero = results.count(0)\n",
    "print(\"異常數量：%d\" %num_of_zero)\n",
    "\n",
    "# 計算機率\n",
    "abnormal_rate = num_of_zero / len(results)\n",
    "\n",
    "print(\"異常率：%.3f\" %abnormal_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
